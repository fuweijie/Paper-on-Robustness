# Awesome papers on adversarial robustness.
##	Review:
######	Adversarial attacks and defenses in images, graphs and text: a review, 2019.
##	Attackers:
######	Explaining and harnessing adversarial examples, 2015, ICLR.
######	Deepfool: a simple and accurate method to fool deep neural networks, 2016,CVPR.
######	Zoo: zeroth order optimization based black-box attacks to deep neural networks without training substitute models, 2017.
######	The limitations of deep learning in adversarial settings, 2018.
######	Interpretable deep learning under fire, 2018.
######	Interpretation of neural networks is fragile, 2019, AAAI.
##	Analysis and insights:
######	Perturbation, optimization and statistics, 2016.
######	Sparse dnns with improved adversarial robustness, 2018, NeurIPS.
######	Attention, please! Adversarial defense via attention rectification and preservation, 2019.
######	Defective convolutional layers learn robust cnns, 2019.
######	Adversarial examples are not bugs, they are features, 2019, NeurIPS.
######	Batch normalization is a cause of adversarial vulnerability, 2019, ICML.
######	Adversarial training can hurt generalization, 2019.
######	Proper network interpretability helps adversarial robustness in classification, 2020, ICML.
######	Exploring the vulnerability of deep neural networks: a study of parameter corruption, 2020.
######	Overfitting in adversarially robust deep learning, 2020, ICML.
######	The curious case of adversarially robust models: more data can help, double descend, or hurt generalization, 2020.
######	Rethinking randomized smoothing for adversarial robustness, 2020.
######	Invariance vs. Robustness of neural networks, 2020.
##	About fake defense:
######	Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples, 2018.
##	Adversarial training with data augumentation:
######	Adversarial machine learning at scale, 2017, ICLR.
######	Mixup inference: better exploiting mixup to defend adversarial attacks, 2019.
######	Towards a unified min-max framework for adversarial exploration and robustness, 2019.
######	Theoretically principled trade-off between robustness and accuracy, 2019.
######	L1-norm double backpropagation adversarial defense, 2019.
######	Learning to defense by learning to attack, 2019.
######	Adversarial vertex mixup: toward better adversarially robust generalization, 2020.
######	Manifold regularization for adversarial robustness, 2020.
######	Curriculum adversarial training, 2020.
##	Denoising on representations:
######	Deepcloak: masking deep neural network models for robustness against adversarial samples, 2017.
######	Adversarial examples detection in deep networks with convolutional filter statistics, 2017, ICCV.
######	Optimal transport classifier: defending against adversarial attacks by regularized deep embedding, 2018.
######	Feature denoising for improving adversarial robustness, 2019, CVPR.
######	Adversarial noise layer: regularize neural network by adding noise, 2019, ICIP.
######	Feature losses for adversarial robustness, 2019.
######	White-box adversarial defense via self-supervised data estimation, 2019.
######	Adversarial defense by stratified convolutional sparse coding, 2019.
##	Regularization via losses:
######	Adversarial robustness through local linearization, 2019, NeurIPS.
######	Adversarial defense by restricting the hidden space of deep neural networks, 2019.
######	Jacobian adversarially regularized networks for robustness, 2020.
######	Towards understanding the regularization of adversarial robustness on neural networks, 2020, ICML.
##	Theory on error bounds:
######	Towards deep neural network architectures robust to adversarial examples, 2014.
######	Limitations of the lipschitz constant as a defense against adversarial examples, 2018.
######	Towards robust neural networks via random self-ensemble, 2018, ECCV.
######	Lipschitz-margin training: scalable certification of perturbation invariance for deep neural networks, 2018, NeurIPS.
######	Lipschitz regularity of deep neural networks: analysis and efficient estimation, 2018, NeurIPS.
######	Efficient and accurate estimation of lipschitz constants for deep neural networks, 2019, NeurIPS.
######	Adversarial learning guarantees for linear hypotheses and neural networks, 2020, ICML.



